{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJfQxGsXeUnN",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Retrieval Augmented Generation (RAG) with Langchain\n",
    "*Using IBM Granite Models*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShNmneLheUnR",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook\n",
    "This notebook contains instructions for performing Retrieval Augumented Generation (RAG). RAG is an architectural pattern that can be used to augment the performance of language models by recalling factual information from a knowledge base, and adding that information to the model query. The most common approach in RAG is to create dense vector representations of the knowledge base in order to retrieve text chunks that are semantically similar to a given user query.\n",
    "\n",
    "RAG use cases include:\n",
    "- Customer service: Answering questions about a product or service using facts from the product documentation.\n",
    "- Domain knowledge: Exploring a specialized domain (e.g., finance) using facts from papers or articles in the knowledge base.\n",
    "- News chat: Chatting about current events by calling up relevant recent news articles.\n",
    "\n",
    "In its simplest form, RAG requires 3 steps:\n",
    "\n",
    "- Initial setup:\n",
    "  - Index knowledge-base passages for efficient retrieval. In this recipe, we take embeddings of the passages, and store them in a vector database.\n",
    "- Upon each user query:\n",
    "  - Retrieve relevant passages from the database. In this recipe, we use an embedding of the query to retrieve semantically similar passages.\n",
    "  - Generate a response by feeding retrieved passage into a large language model, along with the user query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pz6LWpOIeUnS",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up the environment\n",
    "\n",
    "Ensure you are running python 3.10, 3.11, or 3.12 in a freshly-created virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kWJvbpaaeUnT"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >= (3, 10) and sys.version_info < (3, 13), \"Use Python 3.10, 3.11, or 3.12 to run this notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD0Wx5cQeUnV",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLTr3CREeUnW"
   },
   "source": [
    "Granite utils provides some helpful functions for recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Du-vgeoPeUnW",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "a59fc592-2d19-4a33-ecde-7fe7bf8c433b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ibm-granite-community/utils\n",
      "  Cloning https://github.com/ibm-granite-community/utils to /tmp/pip-req-build-qaiy1kmu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /tmp/pip-req-build-qaiy1kmu\n",
      "  Resolved https://github.com/ibm-granite-community/utils to commit da3c800822615230c65b4d4cdee3bc7e48cbfa60\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain_milvus\n",
      "  Downloading langchain_milvus-0.2.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting replicate\n",
      "  Downloading replicate-1.0.7-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting langchain_huggingface[full]\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "Collecting python-dotenv (from ibm-granite-community-utils==0.1.dev81)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (from ibm-granite-community-utils==0.1.dev81) (0.3.70)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from ibm-granite-community-utils==0.1.dev81) (4.14.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.8)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface[full]) (4.1.0)\n",
      "Collecting pymilvus<3.0,>=2.5.7 (from langchain_milvus)\n",
      "  Downloading pymilvus-2.5.14-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev81) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.1)\n",
      "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (75.2.0)\n",
      "Collecting grpcio<=1.67.1,>=1.49.1 (from pymilvus<3.0,>=2.5.7->langchain_milvus)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (5.29.5)\n",
      "Collecting ujson>=2.0.0 (from pymilvus<3.0,>=2.5.7->langchain_milvus)\n",
      "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.11/dist-packages (from pymilvus<3.0,>=2.5.7->langchain_milvus) (2.2.2)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus<3.0,>=2.5.7->langchain_milvus)\n",
      "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface[full]) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface[full]) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface[full]) (1.16.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface[full]) (11.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core->ibm-granite-community-utils==0.1.dev81) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (2025.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full])\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface[full]) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface[full]) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus<3.0,>=2.5.7->langchain_milvus) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface[full]) (3.0.2)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_milvus-0.2.1-py3-none-any.whl (36 kB)\n",
      "Downloading replicate-1.0.7-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymilvus-2.5.14-py3-none-any.whl (236 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.4/236.4 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Building wheels for collected packages: ibm-granite-community-utils, wget\n",
      "  Building wheel for ibm-granite-community-utils (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ibm-granite-community-utils: filename=ibm_granite_community_utils-0.1.dev81-py3-none-any.whl size=12941 sha256=7bbf4a0ef01131bcb205eab3ec84b049f26ed3432cd6578fa012c140cf3ea841\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qobb3fas/wheels/7b/e8/64/5f8c4595097153effea0a6587a85a9ebf314924faf4e61c449\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=c8fa123e534ac4f21699589741a7a8de46a6b032bac062686fbf3be9da1898a5\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
      "Successfully built ibm-granite-community-utils wget\n",
      "Installing collected packages: wget, ujson, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, milvus-lite, marshmallow, httpx-sse, grpcio, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, replicate, pymilvus, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, langchain_milvus, langchain_huggingface, ibm-granite-community-utils, langchain_community\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.73.1\n",
      "    Uninstalling grpcio-1.73.1:\n",
      "      Successfully uninstalled grpcio-1.73.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.67.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 grpcio-1.67.1 httpx-sse-0.4.1 ibm-granite-community-utils-0.1.dev81 langchain_community-0.3.27 langchain_huggingface-0.3.1 langchain_milvus-0.2.1 marshmallow-3.26.1 milvus-lite-2.5.1 mypy-extensions-1.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.10.1 pymilvus-2.5.14 python-dotenv-1.1.1 replicate-1.0.7 typing-inspect-0.9.0 ujson-5.10.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    transformers \\\n",
    "    langchain_community \\\n",
    "    'langchain_huggingface[full]' \\\n",
    "    langchain_milvus \\\n",
    "    replicate \\\n",
    "    wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zNw0xsVeUnX"
   },
   "source": [
    "## Selecting System Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IGf3_vxeUnY"
   },
   "source": [
    "### Choose your Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g9kTNRPZeUnY"
   },
   "source": [
    "Specify the model to use for generating embedding vectors from text.\n",
    "\n",
    "To use a model from a provider other than Huggingface, replace this code cell with one from [this Embeddings Model recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_Embeddings_Models.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "6ae9dcc8b24949418c02286db9aa3ae2",
      "4d434f4655a749fbb543ddcfc35e8034",
      "a399e75f74574639a686f8a2eeff6898",
      "88fe6415a5384048a014d5f72397aef3",
      "6ffab196a75445689a9ace3346396595",
      "bc4108630a6e4e929f09b595e80887c7",
      "585ad117e0704d92878fce53737fa23a",
      "1d51ffc28cd74e25b14e1318d2ab13b9",
      "fbb85efa6c574baba4b8cef3fbe02236",
      "18b3237164274079818c08b33722e42e",
      "53f9b8b75eb24744ad64a3734754771a",
      "c630bbc3ec9c487d823445a054b7c419",
      "834931f4b5c24901b33a25eb3dea30ca",
      "a573921dfde042cfa26b9528e396a75b",
      "d6c5271dc19742769caacd6bdef6bed2",
      "cbf7b838c2254358b8eebe0f5ea6a756",
      "e1a48303ca394707990f6d8df2346892",
      "8f08b2c85a9a4e33b949f5a19926f18f",
      "63bb91c3edcb4ed483e9ac877b06a906",
      "a58ff610d91140f79968632fd6aa103f",
      "d7bae0135985427492a23111b6ad94d2",
      "ed12f94fc58148ae9541c7dfca4f24bc",
      "4af31f930e504503b880111167e88c5c",
      "4eebad95c603472ca0c6cd66597d78b7",
      "44436796f1984080b21a8f32138a2543",
      "7d43f76ffb0649ddb5cc61eb80de2955",
      "3081dc50e33c4b32879d4d9c752a9cbe",
      "f13b33f93ce44dcaa5f853eb2e1ae04d",
      "16b4c8c5343b4d2a9fa58c71f34df0f4",
      "2dfea59a59894df7b8f8ef3682709b28",
      "2036ba7f9f4e4ab287d937834ebec972",
      "6c33cf90cf5d48c1a591f30f40f72bfb",
      "c20911a952e54cfb8859a8b7aaeebd99",
      "9c3cde54c3cc45f3a9f1587c675647e2",
      "4abdb6f10f4b4889a022785066a40fff",
      "a1bd1137ce7e483f9c6708ced05b1f7f",
      "e0853db7c23f40eaba006c876f1c44fa",
      "de6f6b1b3af840358bc0eccdf114bb8b",
      "f8b549bc89cf4259b96dd132cafb4e4b",
      "031a9d0769874391a53b8ad79ef85306",
      "12248d2aabb1460db59906bc91d4ebb1",
      "8935a7d610654943968bbe6e5b6259de",
      "0b4f75ade86a4bb4ba755a2656a72fbc",
      "d96cdac677554c6396522bf1d3379318",
      "2260720510bd40f4b283f768b46de893",
      "0432f15805914aef86cdd2ce2272848a",
      "91e7b10647f840ec9e0b36002aa967f2",
      "91fa27a9e131496789cb7a034d8d2a3c",
      "1a8fa26bf1c1412ebc977b6834a742be",
      "1161474e1b69409e818a1e7c3f32e0a9",
      "b49cb7142387439dac3dbf11b7b1e4f8",
      "44911eb5142648d192950a133993f4df",
      "d8286726ebd342bea4081310e8838127",
      "9920c2ce225f4b4b9446c1b4074e01d2",
      "cf8d381fbaab4f2fa3a9687af89b4ebf",
      "f9ec0ded75f3465ca750a1754ff1e2df",
      "b5f1d6db853d44ea9e4f4296111bf0e6",
      "972c09c2c1a84b39bd7c4ee151b93962",
      "96f99dfe93704813814b22cbf1862990",
      "ea650c9aa5a240399f4e10c1f8c823f7",
      "54d4051f8eb3493ca633105a84ad4b9f",
      "3316b41d5fac4afdbfa25416eb5e6320",
      "54d64aa0b15145298d935c0038d9f9b5",
      "801987600d2b477ba81a96294de205e2",
      "5e32ed1ea52c46fb93565a290f5089ef",
      "5135639d2df54558a087aa23f63e89c5",
      "3ae2f8af8c6e4e2ab9ddf152d35821fb",
      "d44a69c6802d42c6911b3fe6c3274eb7",
      "aaaf613d5ea44c3ca73f8d698180c9b8",
      "cebc250e5e664d06b01814aa1930a0e1",
      "6b51851e14854e6aba9cf99cbc85834f",
      "4c30d854286348dbbd92c0cd25a677d2",
      "8591b30f8c8c4e7bb2ef35c466f662dd",
      "be2008fda1214330889d9580e9d65996",
      "4d671ed17d644fbf9f735ff3ec4e5749",
      "1e4f03417e774ec4805092d19cc4959d",
      "73055dd9b66845bca0528002413a714b",
      "2929fd963adc4aeda4a689435f1e8149",
      "d08111b5ff57426896bfa2c1af21010b",
      "94f1523053644fa0bc009e3524b92eb2",
      "bbcf31597f5240a18113f8d6a9ba1a09",
      "f685db00f048435cb52ec1e9da077b01",
      "914ccd34853843adb78f76d5aa8cbf3e",
      "f9dab50ef6d942d2a1a768c8ca9817b6",
      "62ca3b2e069040608a40435823cc9c00",
      "cc3319bbf377445aa454b4245fc02415",
      "dff3640a01654ec9973a1f2d8b6fbf15",
      "206509a53a6f485987f7f8b65e0ac173",
      "950e199acf4e4a97bbcdaec122a9ceb0",
      "6ce7c5c761234419ae4dd3f6221e5884",
      "81ac29ea51614b6f9ffed815a8668ec9",
      "1f4646df01694a68bc025aa128f87263",
      "cedb04ad270d4cbbb069ddd2803959c5",
      "175409621c304187a9396e8a70f81769",
      "59f5300c7e8744f28f7b4c136a9d5e8c",
      "5cfbae8f6df04a65996f0ad992925770",
      "dc5e0fd4708d4cae9a79253a2bae9d4a",
      "18abc8e9778b4914aba35dd5f195d98e",
      "330e7b4f7e2e4d3594292bb2df9d27ab",
      "fcb0ab99946143598e5aac8ef522c13d",
      "ba4291e9dc164fcfbff5bebabe77141f",
      "0f6a041bb3aa4dbdbaf774c141c48c55",
      "979352e1f3c54e06b118b8732b9309ab",
      "93855ae254804affbc9cca4890db4d34",
      "0b8582cc10f64a2f91ea7400b2813c09",
      "fc1adc2a41f148d489adbcf5399bf8d5",
      "2def5c0cdce042d2850a9248a4e741b9",
      "c6260349fb684bc580300138491a2ed5",
      "23bd9e8f3ad94224811cd26a162d784e",
      "06886ce0af6b4eb596b6b4bb7d5708ef",
      "be23a035ec054a0690b3f8d4b89e7946",
      "c1ec395a8ac34a6bb6e33d5c7915aba4",
      "c97a701b6816455b8112753a5ec51482",
      "28a9703bdd364846bbe71118ca3c83fa",
      "28d853447d4d439dbb1f356ff10f78b9",
      "292db3ac193f4bad8632e2ff19af85e0",
      "ba35389ef2e04090bc3248c922d8c516",
      "71028573541c4c5b85f8f6c18a47f9e5",
      "8769dbffd02f411b8442a3d669d75101",
      "006f02ec241c4983b7a4ee6cfdd16d4c",
      "d657b4956438421f9b7e749c5f64f2be"
     ]
    },
    "id": "p8P1E_VgeUnZ",
    "outputId": "8d6a9a87-2a77-4f2f-fc90-8f0a8375cfda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae9dcc8b24949418c02286db9aa3ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c630bbc3ec9c487d823445a054b7c419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af31f930e504503b880111167e88c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3cde54c3cc45f3a9f1587c675647e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2260720510bd40f4b283f768b46de893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/60.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ec0ded75f3465ca750a1754ff1e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae2f8af8c6e4e2ab9ddf152d35821fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2929fd963adc4aeda4a689435f1e8149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950e199acf4e4a97bbcdaec122a9ceb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb0ab99946143598e5aac8ef522c13d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be23a035ec054a0690b3f8d4b89e7946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "embeddings_model_path = \"ibm-granite/granite-embedding-30m-english\"\n",
    "embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=embeddings_model_path,\n",
    ")\n",
    "embeddings_tokenizer = AutoTokenizer.from_pretrained(embeddings_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHSuGmiteUnZ"
   },
   "source": [
    "### Choose your Vector Database\n",
    "\n",
    "Specify the database to use for storing and retrieving embedding vectors.\n",
    "\n",
    "To connect to a vector database other than Milvus substitute this code cell with one from [this Vector Store recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_Vector_Stores.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ynryASYeUnZ",
    "outputId": "05450ca2-ea61-449c-dbb5-81ea847ecb92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vector database will be saved to /tmp/milvus_57guirpc.db\n"
     ]
    }
   ],
   "source": [
    "from langchain_milvus import Milvus\n",
    "import tempfile\n",
    "\n",
    "db_file = tempfile.NamedTemporaryFile(prefix=\"milvus_\", suffix=\".db\", delete=False).name\n",
    "print(f\"The vector database will be saved to {db_file}\")\n",
    "\n",
    "vector_db = Milvus(\n",
    "    embedding_function=embeddings_model,\n",
    "    connection_args={\"uri\": db_file},\n",
    "    auto_id=True,\n",
    "    index_params={\"index_type\": \"AUTOINDEX\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCLKyvXheUna",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Choose your LLM\n",
    "The LLM will be used for answering the question, given the retrieved text.\n",
    "\n",
    "Select a Granite Code model from the [`ibm-granite`](https://replicate.com/ibm-granite) org on Replicate. Here we use the Replicate Langchain client to connect to the model.\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "G2zcDAAHeUna"
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.3-8b-instruct\"\n",
    "model = Replicate(\n",
    "    model=model_path,\n",
    "    replicate_api_token=get_env_var('REPLICATE_API_TOKEN'),\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLq7FHCZeUna",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Building the Vector Database\n",
    "\n",
    "In this example, we take the State of the Union speech text, split it into chunks, derive embedding vectors using the embedding model, and load it into the vector database for querying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9I5oe0KUeUnb"
   },
   "source": [
    "### Download the document\n",
    "\n",
    "Here we use President Biden's State of the Union address from March 1, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NIl6Xb9deUnb",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "filename = 'state_of_the_union.txt'\n",
    "url = 'https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/data/foundation_models/state_of_the_union.txt'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "  wget.download(url, out=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "086qVuyoeUnb"
   },
   "source": [
    "### Split the document into chunks\n",
    "\n",
    "Split the document into text segments that can fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uP2Gn887eUnb",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "8045a38d-d19a-49f7-d12f-aa7ef92dc2b9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 text document chunks created\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(filename)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer=embeddings_tokenizer,\n",
    "    chunk_size=embeddings_tokenizer.max_len_single_sentence,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "texts = text_splitter.split_documents(documents)\n",
    "doc_id = 0\n",
    "for text in texts:\n",
    "    text.metadata[\"doc_id\"] = (doc_id:=doc_id+1)\n",
    "print(f\"{len(texts)} text document chunks created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlYNNCLpeUnc",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Populate the vector database\n",
    "\n",
    "NOTE: Population of the vector database may take over a minute depending on your embedding model and service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-_DiNMfReUnc",
    "outputId": "bc2437a6-6574-42fe-bac8-3d7e49fe1b4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 documents added to the vector database\n"
     ]
    }
   ],
   "source": [
    "ids = vector_db.add_documents(texts)\n",
    "print(f\"{len(ids)} documents added to the vector database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlfSqMjCeUnc"
   },
   "source": [
    "## Querying the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD6u1OpJeUnc"
   },
   "source": [
    "### Conduct a similarity search\n",
    "\n",
    "Search the database for similar documents by proximity of the embedded vector in vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukfuWzFVeUnc",
    "outputId": "c34ade44-e73c-4383-947f-ab7f6f6062a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 documents returned\n",
      "page_content='Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections. \n",
      "\n",
      "Tonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service. \n",
      "\n",
      "One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \n",
      "\n",
      "And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence. \n",
      "\n",
      "A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \n",
      "\n",
      "And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \n",
      "\n",
      "We can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \n",
      "\n",
      "We’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.  \n",
      "\n",
      "We’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster. \n",
      "\n",
      "We’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders. \n",
      "\n",
      "We can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours. \n",
      "\n",
      "Provide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers. \n",
      "\n",
      "Revise our laws so businesses have the workers they need and families don’t wait decades to reunite. \n",
      "\n",
      "It’s not only the right thing to do—it’s the economically smart thing to do. \n",
      "\n",
      "That’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce.' metadata={'doc_id': 15, 'pk': 459651537341775886, 'source': 'state_of_the_union.txt'}\n",
      "================================================================================\n",
      "page_content='That’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.  \n",
      "\n",
      "So that’s my plan. It will grow the economy and lower costs for families. \n",
      "\n",
      "So what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \n",
      "\n",
      "My plan will not only lower costs to give families a fair shot, it will lower the deficit. \n",
      "\n",
      "The previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \n",
      "\n",
      "But in my administration, the watchdogs have been welcomed back. \n",
      "\n",
      "We’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \n",
      "\n",
      "And tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \n",
      "\n",
      "By the end of this year, the deficit will be down to less than half what it was before I took office.  \n",
      "\n",
      "The only president ever to cut the deficit by more than one trillion dollars in a single year. \n",
      "\n",
      "Lowering your costs also means demanding more competition. \n",
      "\n",
      "I’m a capitalist, but capitalism without competition isn’t capitalism. \n",
      "\n",
      "It’s exploitation—and it drives up prices. \n",
      "\n",
      "When corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \n",
      "\n",
      "We see it happening with ocean carriers moving goods in and out of America. \n",
      "\n",
      "During the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits. \n",
      "\n",
      "Tonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers. \n",
      "\n",
      "And as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.  \n",
      "\n",
      "That ends on my watch. \n",
      "\n",
      "Medicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect.' metadata={'doc_id': 10, 'pk': 459651537341775881, 'source': 'state_of_the_union.txt'}\n",
      "================================================================================\n",
      "page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \n",
      "\n",
      "In this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \n",
      "\n",
      "Let each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \n",
      "\n",
      "Please rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \n",
      "\n",
      "Throughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \n",
      "\n",
      "They keep moving.   \n",
      "\n",
      "And the costs and the threats to America and the world keep rising.   \n",
      "\n",
      "That’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \n",
      "\n",
      "The United States is a member along with 29 other nations. \n",
      "\n",
      "It matters. American diplomacy matters. American resolve matters. \n",
      "\n",
      "Putin’s latest attack on Ukraine was premeditated and unprovoked. \n",
      "\n",
      "He rejected repeated efforts at diplomacy. \n",
      "\n",
      "He thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \n",
      "\n",
      "We prepared extensively and carefully.' metadata={'doc_id': 1, 'pk': 459651537341775872, 'source': 'state_of_the_union.txt'}\n",
      "================================================================================\n",
      "page_content='It’s time for Americans to get back to work and fill our great downtowns again.  People working from home can feel safe to begin to return to the office.   \n",
      "\n",
      "We’re doing that here in the federal government. The vast majority of federal workers will once again work in person. \n",
      "\n",
      "Our schools are open. Let’s keep it that way. Our kids need to be in school. \n",
      "\n",
      "And with 75% of adult Americans fully vaccinated and hospitalizations down by 77%, most Americans can remove their masks, return to work, stay in the classroom, and move forward safely. \n",
      "\n",
      "We achieved this because we provided free vaccines, treatments, tests, and masks. \n",
      "\n",
      "Of course, continuing this costs money. \n",
      "\n",
      "I will soon send Congress a request. \n",
      "\n",
      "The vast majority of Americans have used these tools and may want to again, so I expect Congress to pass it quickly.   \n",
      "\n",
      "Fourth, we will continue vaccinating the world.     \n",
      "\n",
      "We’ve sent 475 Million vaccine doses to 112 countries, more than any other nation. \n",
      "\n",
      "And we won’t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers.' metadata={'doc_id': 13, 'pk': 459651537341775884, 'source': 'state_of_the_union.txt'}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "query = \"What did the president say about Ketanji Brown Jackson?\"\n",
    "docs = vector_db.similarity_search(query)\n",
    "print(f\"{len(docs)} documents returned\")\n",
    "for doc in docs:\n",
    "    print(doc)\n",
    "    print(\"=\" * 80)  # Separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A197QkFCeUnd"
   },
   "source": [
    "## Answering Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63YBaHv1eUnd"
   },
   "source": [
    "### Automate the RAG pipeline\n",
    "\n",
    "Build a RAG chain with the model and the document retriever.\n",
    "\n",
    "First we create the prompts for Granite to perform the RAG query. We use the Granite chat template and supply the placeholder values that the LangChain RAG pipeline will replace.\n",
    "\n",
    "Next, we construct the RAG pipeline by using the Granite prompt templates previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XP-2jpm2eUnd"
   },
   "outputs": [],
   "source": [
    "from ibm_granite_community.langchain import TokenizerChatPromptTemplate, create_stuff_documents_chain\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "# Create a Granite prompt for question-answering with the retrieved context\n",
    "prompt_template = TokenizerChatPromptTemplate.from_template(\"{input}\", tokenizer=tokenizer)\n",
    "\n",
    "# Assemble the retrieval-augmented generation chain\n",
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm=model,\n",
    "    prompt=prompt_template,\n",
    ")\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=vector_db.as_retriever(),\n",
    "    combine_docs_chain=combine_docs_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vhjv1SKaeUnd",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate a retrieval-augmented response to a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_O7tEPNeUnd",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Use the RAG chain to process a question. The document chunks relevant to that question are retrieved and used as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGucyt3heUne",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "2422b275-92e5-47d3-b590-bef983930983",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to the United States Supreme Court, describing her as one of the nation's top legal minds and a consensus builder with support from various groups. He mentioned her background as a former top litigator in private practice, federal public defender, and coming from a family of public school educators and police officers.\n"
     ]
    }
   ],
   "source": [
    "output = rag_chain.invoke({\"input\": query})\n",
    "\n",
    "print(output['answer'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
